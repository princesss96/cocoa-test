{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cocoa Pod Disease: Hybrid CNN\u2013ViT + YOLOv8 Severity (Colab)\n",
    "\n",
    "This notebook trains and runs the pipeline:\n",
    "- **Classification**: CNN / ViT / Concat / Attention Fusion (+ EMA optional)\n",
    "- **Detection**: YOLOv8 lesion (and optionally pod)\n",
    "- **Severity**: `lesion_area / pod_area`\n",
    "\n",
    "Dataset is required (not included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Mount Drive (optional) ===\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) (Option A) Unzip this project (if you uploaded cocoa_hybrid_project.zip) ===\n",
    "!unzip -q cocoa_hybrid_project.zip -d /content/cocoa_hybrid_project\n",
    "%cd /content/cocoa_hybrid_project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3) Install dependencies ===\n",
    "!pip -q install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset folders\n",
    "\n",
    "### Classification dataset structure\n",
    "```\n",
    "data_cls/\n",
    "  train/Healthy, BPR, FPR\n",
    "  val/Healthy, BPR, FPR\n",
    "  test/Healthy, BPR, FPR   (optional)\n",
    "```\n",
    "\n",
    "### YOLO detection dataset structure\n",
    "```\n",
    "data_det/\n",
    "  images/train, images/val\n",
    "  labels/train, labels/val\n",
    "  data.yaml\n",
    "```\n",
    "Recommended YOLO classes: `[pod, lesion]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4) Train classification ===\n",
    "# Edit --data_dir to where your dataset is (Drive path or /content path)\n",
    "!python -m src.train_cls \\\n",
    "  --data_dir data_cls \\\n",
    "  --variant attn \\\n",
    "  --epochs 20 \\\n",
    "  --batch_size 32 \\\n",
    "  --lr 3e-4 \\\n",
    "  --use_ema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5) Train YOLOv8 detection ===\n",
    "# Make sure your data.yaml points to the correct dataset path.\n",
    "!python -m src.train_yolo \\\n",
    "  --data_yaml data_det/data.yaml \\\n",
    "  --model yolov8n.pt \\\n",
    "  --epochs 100 \\\n",
    "  --imgsz 640\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6) Run end-to-end inference + severity ===\n",
    "!python -m src.infer_cls_and_severity \\\n",
    "  --cls_ckpt runs_cls/best.pt \\\n",
    "  --yolo_ckpt runs/detect/train/weights/best.pt \\\n",
    "  --image_path path/to/one_image.jpg \\\n",
    "  --out_path prediction.jpg\n",
    "\n",
    "from PIL import Image\n",
    "Image.open('prediction.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) Explainability (optional): Grad-CAM + ViT attention rollout ===\n",
    "!python -m src.xai --cls_ckpt runs_cls/best.pt --image_path path/to/one_image.jpg --mode both --out_dir xai_out\n",
    "\n",
    "from PIL import Image\n",
    "display(Image.open('xai_out/gradcam_cnn.jpg'))\n",
    "display(Image.open('xai_out/vit_attention_rollout.jpg'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}